{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289d284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlib\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ddd4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.genfromtxt('data/train_data.csv', delimiter=',')\n",
    "file = np.delete(file, (0), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64eeb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba44436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920d7d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(feature, cv2.ml.ROW_SAMPLE, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df64339",
   "metadata": {},
   "source": [
    "#### 계산해야 하는 feature\n",
    "* degree, Diff_X, Diff_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7831af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nose_Point(result, image_width, image_height) :\n",
    "    Nose_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width\n",
    "    Nose_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height\n",
    "\n",
    "    return Nose_X, Nose_Y\n",
    "\n",
    "def Compute_Neck(result, image_width, image_height) :\n",
    "    L_Shoulder_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * image_width\n",
    "    R_Shoulder_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * image_width\n",
    "    Neck_X = (L_Shoulder_X + R_Shoulder_X) / float(2.0)\n",
    "    \n",
    "    R_Shoulder_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * image_height\n",
    "    L_Shoulder_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * image_height\n",
    "    Neck_Y = (L_Shoulder_Y + R_Shoulder_Y) / float(2.0)\n",
    "\n",
    "    return Neck_X, Neck_Y\n",
    "\n",
    "def Compute_Diff(Nose_X, Nose_Y, Neck_X, Neck_Y):\n",
    "    Diff_X = Neck_X - Nose_X\n",
    "    Diff_Y = Neck_Y - Nose_Y\n",
    "    return Diff_X, Diff_Y\n",
    "\n",
    "def Comput_Degree(Nose_X, Nose_Y, Neck_X, Neck_Y):\n",
    "    AB = np.sqrt((Nose_X - Neck_X) ** 2 + (Nose_Y - Neck_Y) ** 2)\n",
    "    AC = np.abs(Nose_X - Neck_X)\n",
    "    cos = AC / AB\n",
    "    degree = np.degrees(cos)\n",
    "    return degree\n",
    "\n",
    "def Point_Eye(result, image_width, image_height):\n",
    "    R_Eye_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_EYE].x * image_width\n",
    "    R_Eye_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_EYE].y * image_height\n",
    "\n",
    "    L_Eye_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_EYE].x * image_width\n",
    "    L_Eye_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_EYE].y * image_height\n",
    "    return int(R_Eye_X), int(R_Eye_Y), int(L_Eye_X), int(L_Eye_Y)\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6337ff6",
   "metadata": {},
   "source": [
    "#### eye detect model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a701075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/eye_detecting.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a46bcd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('dlib_eye/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.VideoCapture(\"test.mp4\")\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "    \n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      break\n",
    "    \n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    result = pose.process(image)\n",
    "    \n",
    "    # compute degree and diff\n",
    "    try:\n",
    "        Nose_X, Nose_Y = Nose_Point(result, image_width, image_height)\n",
    "        Neck_X, Neck_Y = Compute_Neck(result, image_width, image_height)\n",
    "        Diff_X, Diff_Y = Compute_Diff(Nose_X, Nose_Y, Neck_X, Neck_Y)\n",
    "        degree = Comput_Degree(Nose_X, Nose_Y, Neck_X, Neck_Y)\n",
    "        data = np.array([degree, Diff_X, Diff_Y], dtype = np.float32)\n",
    "        data = data.reshape(1,3)\n",
    "    \n",
    "        ret, label, neighbours, dist = knn.findNearest(data, 2)    \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        faces = detector(gray)\n",
    "        for face in faces:\n",
    "            shapes = predictor(gray, face) \n",
    "            shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "            eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "            eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "            eye_img_l = cv2.resize(eye_img_l, dsize=(34,26))\n",
    "            eye_img_r = cv2.resize(eye_img_r, dsize=(34,26))\n",
    "            eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "        \n",
    "            eye_img_l3 = np.reshape(eye_img_l ,(26,34,1))\n",
    "            eye_img_r3 = np.reshape(eye_img_r ,(26,34,1))\n",
    "            cv2_imshow(eye_img_l)\n",
    "            cv2_imshow(eye_img_r)\n",
    "            r = model.predict(np.expand_dims(eye_img_r3, axis = 0))\n",
    "            l = model.predict(np.expand_dims(eye_img_l3, axis = 0))\n",
    "        \n",
    "            if (int(r[0])==1 or int(l[0]) == 1) : category = 0\n",
    "            if (int(r[0])==0 and int(l[0]) == 0) : category = 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # Draw the pose annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        result.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    if label == 1:\n",
    "        text = \"Drowsy\"\n",
    "    else:\n",
    "        text = \"NonDorwsy\"\n",
    "    \n",
    "    cv2.putText(image, text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('MediaPipe Pose', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435c6ce",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ec96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file = np.genfromtxt('data/train_data.csv', delimiter=',')\n",
    "file = np.delete(file, (0), axis = 0)\n",
    "\n",
    "feature = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(feature, cv2.ml.ROW_SAMPLE, label)\n",
    "\n",
    "def Nose_Point(result, image_width, image_height) :\n",
    "    Nose_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width\n",
    "    Nose_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height\n",
    "\n",
    "    return Nose_X, Nose_Y\n",
    "\n",
    "def Compute_Neck(result, image_width, image_height) :\n",
    "    L_Shoulder_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * image_width\n",
    "    R_Shoulder_X = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * image_width\n",
    "    Neck_X = (L_Shoulder_X + R_Shoulder_X) / float(2.0)\n",
    "    \n",
    "    R_Shoulder_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * image_height\n",
    "    L_Shoulder_Y = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * image_height\n",
    "    Neck_Y = (L_Shoulder_Y + R_Shoulder_Y) / float(2.0)\n",
    "\n",
    "    return Neck_X, Neck_Y\n",
    "\n",
    "def Compute_Diff(Nose_X, Nose_Y, Neck_X, Neck_Y):\n",
    "    Diff_X = Neck_X - Nose_X\n",
    "    Diff_Y = Neck_Y - Nose_Y\n",
    "    return Diff_X, Diff_Y\n",
    "\n",
    "def Comput_Degree(Nose_X, Nose_Y, Neck_X, Neck_Y):\n",
    "    AB = np.sqrt((Nose_X - Neck_X) ** 2 + (Nose_Y - Neck_Y) ** 2)\n",
    "    AC = np.abs(Nose_X - Neck_X)\n",
    "    cos = AC / AB\n",
    "    degree = np.degrees(cos)\n",
    "    return degree\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    result = pose.process(image)\n",
    "    \n",
    "    # compute degree and diff\n",
    "    Nose_X, Nose_Y = Nose_Point(result, image_width, image_height)\n",
    "    Neck_X, Neck_Y = Compute_Neck(result, image_width, image_height)\n",
    "    Diff_X, Diff_Y = Compute_Diff(Nose_X, Nose_Y, Neck_X, Neck_Y)\n",
    "    degree = Comput_Degree(Nose_X, Nose_Y, Neck_X, Neck_Y)\n",
    "    data = np.array([degree, Diff_X, Diff_Y], dtype = np.float32)\n",
    "    data = data.reshape(1,3)\n",
    "    \n",
    "    ret, label, neighbours, dist = knn.findNearest(data, 2)    \n",
    "    \n",
    "\n",
    "    # Draw the pose annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        result.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    if label == 1:\n",
    "        text = \"Drowsy\"\n",
    "    else:\n",
    "        text = \"NonDorwsy\"\n",
    "    \n",
    "    cv2.putText(image, text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('MediaPipe Pose', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4a977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret_val, img = cam.read() # 캠 이미지 불러오기\n",
    " \n",
    "    cv2.imshow(\"Cam Viewer\",img) # 불러온 이미지 출력하기\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break  # esc to quit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651f667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
